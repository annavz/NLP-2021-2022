{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ДЗ 1 Анна Запорощенко\n",
    "\n",
    "1. Ссылки и тексты в файле corpus.xlsx. Все тексты представляют собой новостные статьи из www.dw.com Ключевые слова представлены в виде слов и словосочетаний, чаще в начальной форме (иногда допускается множествыенное число). Представляют собой теги-гиперссылки, по которым можно найти новости с пхожей тематикой. \n",
    "2. Уже размеченные ключевые слова, выделенные мной, их пересечение и конечный список с комментарием даны в файле corpus.xlsx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import RAKE\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "from summa import keywords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('russian')\n",
    "m = MorphAnalyzer()\n",
    "def normalize_text(text):\n",
    "    lemmas = []\n",
    "    for t in simple_word_tokenize(text):\n",
    "        lemmas.append(\n",
    "            m.parse(t)[0].normal_form\n",
    "        )\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_excel(r\"corpus.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Текст</th>\n",
       "      <th>DW ключевые слова</th>\n",
       "      <th>Выделенные ключевые слова</th>\n",
       "      <th>Пересечение</th>\n",
       "      <th>Окончательный список ключевых слов</th>\n",
       "      <th>Комментарий</th>\n",
       "      <th>Ссылка</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Кто следующий? Бездомность без прикрас\\nБездом...</td>\n",
       "      <td>бездомные, безработные, выставка \"Кто следующи...</td>\n",
       "      <td>бездомность, Мюнхен, бездомные, безработные, в...</td>\n",
       "      <td>бездомные, безработные, Мюнхен, архитектура, в...</td>\n",
       "      <td>бездомность; бездомные; безработные; Мюнхен; а...</td>\n",
       "      <td>Название выставки лучше исключить из-за наличи...</td>\n",
       "      <td>https://www.dw.com/ru/kto-sledujuchij-bezdomno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Когда чрезмерная диагностика и терапия могут н...</td>\n",
       "      <td>диагностика, чрезмерная диагностика, медицина,...</td>\n",
       "      <td>медицина, чрезмерная диагностика и терапия, оп...</td>\n",
       "      <td>медицина, оперативное вмешательство</td>\n",
       "      <td>медицина; чрезмерная диагностика; терапия; опе...</td>\n",
       "      <td>В целом теги получились практически идентичные...</td>\n",
       "      <td>https://www.dw.com/ru/kogda-chrezmernaja-diagn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Зачем немецкому стартапу хлебные крошки\\nКарто...</td>\n",
       "      <td>немецкая кухня, картофельные кнедли, кулинарны...</td>\n",
       "      <td>кнедли, клопсы, кулинарный стартап, хлеб, реце...</td>\n",
       "      <td>кулинарный стартап, блюда из остатков</td>\n",
       "      <td>кулинарный стартап; блюда из остатков; хлеб; к...</td>\n",
       "      <td>Изначально проставлено очень много общих тегов...</td>\n",
       "      <td>https://www.dw.com/ru/zachem-nemeckomu-startap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Зачем немецким университетам становиться более...</td>\n",
       "      <td>экологичность, учеба в Германии, образование в...</td>\n",
       "      <td>экологичность, Германия, университет, отказать...</td>\n",
       "      <td>экологичность</td>\n",
       "      <td>экологичность; Германия; университет; климатич...</td>\n",
       "      <td>\"Защита окружающей среды\" (не встречается в т...</td>\n",
       "      <td>https://www.dw.com/ru/zachem-nemeckim-universi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Текст  \\\n",
       "0  Кто следующий? Бездомность без прикрас\\nБездом...   \n",
       "1  Когда чрезмерная диагностика и терапия могут н...   \n",
       "2  Зачем немецкому стартапу хлебные крошки\\nКарто...   \n",
       "3  Зачем немецким университетам становиться более...   \n",
       "\n",
       "                                   DW ключевые слова  \\\n",
       "0  бездомные, безработные, выставка \"Кто следующи...   \n",
       "1  диагностика, чрезмерная диагностика, медицина,...   \n",
       "2  немецкая кухня, картофельные кнедли, кулинарны...   \n",
       "3  экологичность, учеба в Германии, образование в...   \n",
       "\n",
       "                           Выделенные ключевые слова  \\\n",
       "0  бездомность, Мюнхен, бездомные, безработные, в...   \n",
       "1  медицина, чрезмерная диагностика и терапия, оп...   \n",
       "2  кнедли, клопсы, кулинарный стартап, хлеб, реце...   \n",
       "3  экологичность, Германия, университет, отказать...   \n",
       "\n",
       "                                         Пересечение  \\\n",
       "0  бездомные, безработные, Мюнхен, архитектура, в...   \n",
       "1                медицина, оперативное вмешательство   \n",
       "2              кулинарный стартап, блюда из остатков   \n",
       "3                                      экологичность   \n",
       "\n",
       "                  Окончательный список ключевых слов  \\\n",
       "0  бездомность; бездомные; безработные; Мюнхен; а...   \n",
       "1  медицина; чрезмерная диагностика; терапия; опе...   \n",
       "2  кулинарный стартап; блюда из остатков; хлеб; к...   \n",
       "3  экологичность; Германия; университет; климатич...   \n",
       "\n",
       "                                         Комментарий  \\\n",
       "0  Название выставки лучше исключить из-за наличи...   \n",
       "1  В целом теги получились практически идентичные...   \n",
       "2  Изначально проставлено очень много общих тегов...   \n",
       "3   \"Защита окружающей среды\" (не встречается в т...   \n",
       "\n",
       "                                              Ссылка  \n",
       "0  https://www.dw.com/ru/kto-sledujuchij-bezdomno...  \n",
       "1  https://www.dw.com/ru/kogda-chrezmernaja-diagn...  \n",
       "2  https://www.dw.com/ru/zachem-nemeckomu-startap...  \n",
       "3  https://www.dw.com/ru/zachem-nemeckim-universi...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. \n",
    "#### RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем анализатор списком стоп-слов\n",
    "rake = RAKE.Rake(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['RAKE'] = np.nan\n",
    "for num, row in corpus.iterrows():\n",
    "    r = rake.run(normalize_text(row['Текст']), maxWords=3, minFrequency=2)\n",
    "    r = [i[0] for i in r][:11]\n",
    "    r = '; '.join(r)\n",
    "    corpus.loc[num, 'RAKE'] = r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. #### TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['TextRank'] = np.nan\n",
    "for num, row in corpus.iterrows():\n",
    "    rt = keywords.keywords(normalize_text(row['Текст']), language='russian', additional_stopwords=stop, scores=True)\n",
    "    rt = [i[0] for i in rt][:11]\n",
    "    rt = '; '.join(rt)\n",
    "    corpus.loc[num, 'TextRank'] = rt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. #### Tf*Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), stop_words=stop)\n",
    "texts = corpus['Текст'].tolist()\n",
    "texts = [normalize_text(text) for text in texts]\n",
    "texts = vectorizer.fit_transform(texts)\n",
    "words = np.array(vectorizer.get_feature_names())\n",
    "args = np.argsort(texts.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['TfIdf'] = np.nan\n",
    "for num, row in corpus.iterrows():\n",
    "    tfidf = words[args[num]][::-1][:10]\n",
    "    tfidf = '; '.join(tfidf)\n",
    "    corpus.loc[num, 'TfIdf'] = tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Текст</th>\n",
       "      <th>DW ключевые слова</th>\n",
       "      <th>Выделенные ключевые слова</th>\n",
       "      <th>Пересечение</th>\n",
       "      <th>Окончательный список ключевых слов</th>\n",
       "      <th>Комментарий</th>\n",
       "      <th>Ссылка</th>\n",
       "      <th>RAKE</th>\n",
       "      <th>TextRank</th>\n",
       "      <th>TfIdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Кто следующий? Бездомность без прикрас\\nБездом...</td>\n",
       "      <td>бездомные, безработные, выставка \"Кто следующи...</td>\n",
       "      <td>бездомность, Мюнхен, бездомные, безработные, в...</td>\n",
       "      <td>бездомные, безработные, Мюнхен, архитектура, в...</td>\n",
       "      <td>бездомность; бездомные; безработные; Мюнхен; а...</td>\n",
       "      <td>Название выставки лучше исключить из-за наличи...</td>\n",
       "      <td>https://www.dw.com/ru/kto-sledujuchij-bezdomno...</td>\n",
       "      <td>проблема бездомность; проблема; город; оказать...</td>\n",
       "      <td>бездомность; бездомный; жильё; социальный; пом...</td>\n",
       "      <td>бездомность; проблема; человек; выставка; соци...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Когда чрезмерная диагностика и терапия могут н...</td>\n",
       "      <td>диагностика, чрезмерная диагностика, медицина,...</td>\n",
       "      <td>медицина, чрезмерная диагностика и терапия, оп...</td>\n",
       "      <td>медицина, оперативное вмешательство</td>\n",
       "      <td>медицина; чрезмерная диагностика; терапия; опе...</td>\n",
       "      <td>В целом теги получились практически идентичные...</td>\n",
       "      <td>https://www.dw.com/ru/kogda-chrezmernaja-diagn...</td>\n",
       "      <td>рак простата; чрезмерный диагностика; врач; те...</td>\n",
       "      <td>врач; мочить; который; терапия мочь; здоровье;...</td>\n",
       "      <td>врач; диагностика; лечение; пациент; терапия; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Зачем немецкому стартапу хлебные крошки\\nКарто...</td>\n",
       "      <td>немецкая кухня, картофельные кнедли, кулинарны...</td>\n",
       "      <td>кнедли, клопсы, кулинарный стартап, хлеб, реце...</td>\n",
       "      <td>кулинарный стартап, блюда из остатков</td>\n",
       "      <td>кулинарный стартап; блюда из остатков; хлеб; к...</td>\n",
       "      <td>Изначально проставлено очень много общих тегов...</td>\n",
       "      <td>https://www.dw.com/ru/zachem-nemeckomu-startap...</td>\n",
       "      <td>рассказывать жанин трапп; сандра ляйтнер; кнед...</td>\n",
       "      <td>кнедлить; кнедлей; кнедль; хлебо; чёрствый хле...</td>\n",
       "      <td>кнедлить; хлеб; хлебный; кнедлей; картофельный...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Зачем немецким университетам становиться более...</td>\n",
       "      <td>экологичность, учеба в Германии, образование в...</td>\n",
       "      <td>экологичность, Германия, университет, отказать...</td>\n",
       "      <td>экологичность</td>\n",
       "      <td>экологичность; Германия; университет; климатич...</td>\n",
       "      <td>\"Защита окружающей среды\" (не встречается в т...</td>\n",
       "      <td>https://www.dw.com/ru/zachem-nemeckim-universi...</td>\n",
       "      <td>университетский столовый; martin herrmann; это...</td>\n",
       "      <td>это; немецкий университет; экологичный; стать;...</td>\n",
       "      <td>вуз; университет; это; командировка; берлин; с...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Текст  \\\n",
       "0  Кто следующий? Бездомность без прикрас\\nБездом...   \n",
       "1  Когда чрезмерная диагностика и терапия могут н...   \n",
       "2  Зачем немецкому стартапу хлебные крошки\\nКарто...   \n",
       "3  Зачем немецким университетам становиться более...   \n",
       "\n",
       "                                   DW ключевые слова  \\\n",
       "0  бездомные, безработные, выставка \"Кто следующи...   \n",
       "1  диагностика, чрезмерная диагностика, медицина,...   \n",
       "2  немецкая кухня, картофельные кнедли, кулинарны...   \n",
       "3  экологичность, учеба в Германии, образование в...   \n",
       "\n",
       "                           Выделенные ключевые слова  \\\n",
       "0  бездомность, Мюнхен, бездомные, безработные, в...   \n",
       "1  медицина, чрезмерная диагностика и терапия, оп...   \n",
       "2  кнедли, клопсы, кулинарный стартап, хлеб, реце...   \n",
       "3  экологичность, Германия, университет, отказать...   \n",
       "\n",
       "                                         Пересечение  \\\n",
       "0  бездомные, безработные, Мюнхен, архитектура, в...   \n",
       "1                медицина, оперативное вмешательство   \n",
       "2              кулинарный стартап, блюда из остатков   \n",
       "3                                      экологичность   \n",
       "\n",
       "                  Окончательный список ключевых слов  \\\n",
       "0  бездомность; бездомные; безработные; Мюнхен; а...   \n",
       "1  медицина; чрезмерная диагностика; терапия; опе...   \n",
       "2  кулинарный стартап; блюда из остатков; хлеб; к...   \n",
       "3  экологичность; Германия; университет; климатич...   \n",
       "\n",
       "                                         Комментарий  \\\n",
       "0  Название выставки лучше исключить из-за наличи...   \n",
       "1  В целом теги получились практически идентичные...   \n",
       "2  Изначально проставлено очень много общих тегов...   \n",
       "3   \"Защита окружающей среды\" (не встречается в т...   \n",
       "\n",
       "                                              Ссылка  \\\n",
       "0  https://www.dw.com/ru/kto-sledujuchij-bezdomno...   \n",
       "1  https://www.dw.com/ru/kogda-chrezmernaja-diagn...   \n",
       "2  https://www.dw.com/ru/zachem-nemeckomu-startap...   \n",
       "3  https://www.dw.com/ru/zachem-nemeckim-universi...   \n",
       "\n",
       "                                                RAKE  \\\n",
       "0  проблема бездомность; проблема; город; оказать...   \n",
       "1  рак простата; чрезмерный диагностика; врач; те...   \n",
       "2  рассказывать жанин трапп; сандра ляйтнер; кнед...   \n",
       "3  университетский столовый; martin herrmann; это...   \n",
       "\n",
       "                                            TextRank  \\\n",
       "0  бездомность; бездомный; жильё; социальный; пом...   \n",
       "1  врач; мочить; который; терапия мочь; здоровье;...   \n",
       "2  кнедлить; кнедлей; кнедль; хлебо; чёрствый хле...   \n",
       "3  это; немецкий университет; экологичный; стать;...   \n",
       "\n",
       "                                               TfIdf  \n",
       "0  бездомность; проблема; человек; выставка; соци...  \n",
       "1  врач; диагностика; лечение; пациент; терапия; ...  \n",
       "2  кнедлить; хлеб; хлебный; кнедлей; картофельный...  \n",
       "3  вуз; университет; это; командировка; берлин; с...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Выберем шаблоны из списка эталонных КС."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['бездомность; бездомные; безработные; Мюнхен; архитектура; социальное неравенство; проблема бездомных',\n",
       " 'медицина; чрезмерная диагностика; терапия; оперативное вмешательство; операция; врачебная ошибка',\n",
       " 'кулинарный стартап; блюда из остатков; хлеб; кнедли; рецепты; немецкая кухня; клопсы',\n",
       " 'экологичность; Германия; университет; климатическая нейтральность; отказаться от мяса; зеленое электричество; онлайн']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['Окончательный список ключевых слов'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NOUN\n",
    "* ADJ — или субстантивированные прилагательные. Парсер в изоляции может посчитать их обычными прилагательными.\n",
    "* ADJ + NOUN\n",
    "* NOUN + NOUN\n",
    "* NOUN + PREP + NOUN\n",
    "* VERB + PREP + NOUN\n",
    "\n",
    "С помощью всех шаблонов будем фильтровать полученные с помощью алгоритмов КС. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b3503b834044829c27aa76099d3842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading https://raw.githubusercontent.com/stanfordnlp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 21:56:36 INFO: Downloading default packages for language: ru (Russian)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 21:56:37 INFO: File exists: C:\\Users\\VADIK\\stanza_resources\\ru\\default.zip.\n",
      "2021-11-07 21:56:41 INFO: Finished downloading models and saved to C:\\Users\\VADIK\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "stanza.download(\"ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 21:56:41 INFO: Loading these models for language: ru (Russian):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | syntagrus |\n",
      "| pos       | syntagrus |\n",
      "| lemma     | syntagrus |\n",
      "| depparse  | syntagrus |\n",
      "| ner       | wikiner   |\n",
      "=========================\n",
      "\n",
      "2021-11-07 21:56:41 INFO: Use device: cpu\n",
      "2021-11-07 21:56:41 INFO: Loading: tokenize\n",
      "2021-11-07 21:56:41 INFO: Loading: pos\n",
      "2021-11-07 21:56:41 INFO: Loading: lemma\n",
      "2021-11-07 21:56:41 INFO: Loading: depparse\n",
      "2021-11-07 21:56:41 INFO: Loading: ner\n",
      "2021-11-07 21:56:42 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(\"ru\")\n",
    "methods = ['RAKE', 'TextRank', 'TfIdf']\n",
    "for method in methods:\n",
    "    corpus[method + '_filtered'] = np.nan\n",
    "    for num, row in corpus.iterrows():\n",
    "        keywords = row[method].split('; ')\n",
    "        final_keywords = []\n",
    "        for keyword in keywords:\n",
    "            parsed_keyword = nlp(keyword)\n",
    "            tokens = parsed_keyword.to_dict()[0]\n",
    "            if ((len(tokens) == 1) and \n",
    "                (tokens[0]['upos'] in ['NOUN', 'ADJ'])):\n",
    "                final_keywords.append(parsed_keyword.text)\n",
    "            elif ((len(tokens) == 2) and \n",
    "                  (tokens[0]['upos'] in ['NOUN', 'ADJ']) and\n",
    "                  (tokens[1]['upos'] == 'NOUN')):\n",
    "                final_keywords.append(parsed_keyword.text)\n",
    "            elif ((len(tokens) == 3) and\n",
    "                  (tokens[0]['upos'] in ['NOUN', 'VERB']) and\n",
    "                  (tokens[1]['upos'] == 'PREP') and\n",
    "                  (tokens[2]['upos'] == 'NOUN')):\n",
    "                final_keywords.append(parsed_keyword.text)\n",
    "        final_keywords = '; '.join(final_keywords)\n",
    "        corpus.loc[num, method + '_filtered'] = final_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Лемматизируем эталонный список ключевых слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, row in corpus.iterrows():\n",
    "    text = row['Окончательный список ключевых слов'].split('; ')\n",
    "    text = [normalize_text(word) for word in text]\n",
    "    text = '; '.join(text)\n",
    "    corpus.loc[num, 'Окончательный список ключевых слов'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake = set('; '.join(corpus['RAKE'].tolist()).split('; '))\n",
    "rake_filtered = set('; '.join(corpus['RAKE_filtered'].tolist()).split('; '))\n",
    "textrank = set('; '.join(corpus['TextRank'].tolist()).split('; '))\n",
    "textrank_filtered = set('; '.join(corpus['TextRank_filtered'].tolist()).split('; '))\n",
    "tfidf = set('; '.join(corpus['TfIdf'].tolist()).split('; '))\n",
    "tfidf_filtered = set('; '.join(corpus['TfIdf_filtered'].tolist()).split('; '))\n",
    "gold_keywords = set('; '.join(corpus['Окончательный список ключевых слов'].tolist()).split('; '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAKE vs RAKE_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score \t\t RAKE \t\t\t RAKE_filtered\n",
      "precision \t 0.13953488372093023 \t 0.16129032258064516\n",
      "recall \t\t 0.2222222222222222 \t 0.18518518518518517\n",
      "f_score \t 0.17142857142857143 \t 0.17241379310344826\n"
     ]
    }
   ],
   "source": [
    "TP = len(gold_keywords.intersection(rake))\n",
    "TP_FP = len(rake)\n",
    "TP_FN = len(gold_keywords)\n",
    "precision = TP / TP_FP\n",
    "recall = TP / TP_FN\n",
    "f_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "TP_f = len(gold_keywords.intersection(rake_filtered))\n",
    "TP_FP_f = len(rake_filtered)\n",
    "TP_FN_f = len(gold_keywords)\n",
    "precision_f = TP_f / TP_FP_f\n",
    "recall_f = TP_f / TP_FN_f\n",
    "f_score_f = 2 * precision_f * recall_f / (precision_f + recall_f)\n",
    "print('score \\t\\t RAKE \\t\\t\\t RAKE_filtered')\n",
    "print('precision \\t {} \\t {}'.format(precision, precision_f))\n",
    "print('recall \\t\\t {} \\t {}'.format(recall, recall_f))\n",
    "print('f_score \\t {} \\t {}'.format(f_score, f_score_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextRank vs TextRank_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score \t\t TextRank \t\t TextRank_filtered\n",
      "precision \t 0.11904761904761904 \t 0.14285714285714285\n",
      "recall \t\t 0.18518518518518517 \t 0.14814814814814814\n",
      "f_score \t 0.14492753623188406 \t 0.14545454545454545\n"
     ]
    }
   ],
   "source": [
    "TP = len(gold_keywords.intersection(textrank))\n",
    "TP_FP = len(textrank)\n",
    "TP_FN = len(gold_keywords)\n",
    "precision = TP / TP_FP\n",
    "recall = TP / TP_FN\n",
    "f_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "TP_f = len(gold_keywords.intersection(textrank_filtered))\n",
    "TP_FP_f = len(textrank_filtered)\n",
    "TP_FN_f = len(gold_keywords)\n",
    "precision_f = TP_f / TP_FP_f\n",
    "recall_f = TP_f / TP_FN_f\n",
    "f_score_f = 2 * precision_f * recall_f / (precision_f + recall_f)\n",
    "print('score \\t\\t TextRank \\t\\t TextRank_filtered')\n",
    "print('precision \\t {} \\t {}'.format(precision, precision_f))\n",
    "print('recall \\t\\t {} \\t {}'.format(recall, recall_f))\n",
    "print('f_score \\t {} \\t {}'.format(f_score, f_score_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfIdf vs TfIdf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score \t\t TfIdf \t\t\t TfIdf_filtered\n",
      "precision \t 0.2 \t\t\t 0.19444444444444445\n",
      "recall \t\t 0.2962962962962963 \t 0.25925925925925924\n",
      "f_score \t 0.23880597014925375 \t 0.2222222222222222\n"
     ]
    }
   ],
   "source": [
    "TP = len(gold_keywords.intersection(tfidf))\n",
    "TP_FP = len(tfidf)\n",
    "TP_FN = len(gold_keywords)\n",
    "precision = TP / TP_FP\n",
    "recall = TP / TP_FN\n",
    "f_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "TP_f = len(gold_keywords.intersection(tfidf_filtered))\n",
    "TP_FP_f = len(tfidf_filtered)\n",
    "TP_FN_f = len(gold_keywords)\n",
    "precision_f = TP_f / TP_FP_f\n",
    "recall_f = TP_f / TP_FN_f\n",
    "f_score_f = 2 * precision_f * recall_f / (precision_f + recall_f)\n",
    "print('score \\t\\t TfIdf \\t\\t\\t TfIdf_filtered')\n",
    "print('precision \\t {} \\t\\t\\t {}'.format(precision, precision_f))\n",
    "print('recall \\t\\t {} \\t {}'.format(recall, recall_f))\n",
    "print('f_score \\t {} \\t {}'.format(f_score, f_score_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Анализ ошибок\n",
    "    * неправильная лемматизация и, соответственно, изменение части речи: кнедли — кнедлить. Такие проблемы немного ухудшают работу отфильтрованных версий, так как по сути правильно выделенные слова будут отфильтровываться шаблоном (так как шаблона VERB не было)\n",
    "    * выделение слов, которые участвуют в коллокациях, как-то: \"проблема бездомных\", \"бездомный\", \"проблема\". В этом случае слово \"проблема\" будет считаться ошибочным. Возможно, стоит убирать слова, которые уже входят в коллокации, чтобы не было повторов.\n",
    "    * выделение слов, которые отображают суть, но являются слишком частными, как-то: zoom. В тексте идет речь о переходе в онлайн-формат и упоминается это программа, но использовать слово zoom как ключевое кажется неправильным, потому что название программы — слишком детальная информация. Можно попытаться использовать иерархические сети, связывающие понятия, как WordNet, и из выделенных ключевых слов пытаться выбрать более общие концепты.\n",
    "    * плохо выделяются сложные фразы, фразы с предлогами из-за низкой частотности. Возможно, значимость таких фраз стоит попробовать повысить с помощью учета частотности самостоятельных слов, которые в нее входят.\n",
    "    \n",
    "Отдельно хочется сказать о том, что ключевые слова в нынешнем виде пригодны для оценки, но не для использования, так как внутри фраз слова стоят в начальной форме. Необходимо либо с помощью шаблонов ставить выделенные КС в нужную форму, либо уже после вычленять из текста формы, в которых они стояли, и после использовать наиболее пригодную (например, ту, где главное слово  именной группы стоит в именительном падеже)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
